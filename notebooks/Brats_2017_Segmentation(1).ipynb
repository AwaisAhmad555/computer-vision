{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Brats_2017_Segmentation.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"16XJszitq0LU68frORafT2DDobOTuyqm0","authorship_tag":"ABX9TyOMzLMKDWCB8U89wBF5gqqs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"-qMklRmlwxvZ","executionInfo":{"status":"ok","timestamp":1652246740361,"user_tz":-300,"elapsed":15683,"user":{"displayName":"Awais Ahmad","userId":"17510577265023244828"}},"outputId":"aa421a0a-7813-4759-9b40-1bf4b21a5aed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorlayer\n","  Downloading tensorlayer-2.2.5-py3-none-any.whl (381 kB)\n","\u001b[?25l\r\u001b[K     |▉                               | 10 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 40 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 51 kB 3.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |██████                          | 71 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 81 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 92 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 102 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 122 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 133 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 143 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 163 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 174 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 184 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 194 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 204 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 215 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 235 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 245 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 256 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 266 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 276 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 286 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 296 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 307 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 317 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 327 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 337 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 348 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 358 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 368 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 378 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 381 kB 3.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from tensorlayer) (1.21.6)\n","Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorlayer) (1.4.1)\n","Requirement already satisfied: h5py>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorlayer) (3.1.0)\n","Collecting imageio>=2.5.0\n","  Downloading imageio-2.19.1-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 56.1 MB/s \n","\u001b[?25hRequirement already satisfied: cloudpickle>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from tensorlayer) (1.3.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorlayer) (1.14.0)\n","Collecting progressbar2>=3.39.3\n","  Downloading progressbar2-4.0.0-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorlayer) (2.23.0)\n","Requirement already satisfied: scikit-image>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorlayer) (0.18.3)\n","Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorlayer) (1.0.2)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9->tensorlayer) (1.5.2)\n","Collecting pillow>=8.3.2\n","  Downloading Pillow-9.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n","\u001b[K     |████████████████████████████████| 4.3 MB 31.4 MB/s \n","\u001b[?25hRequirement already satisfied: python-utils>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2>=3.39.3->tensorlayer) (3.1.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.21.0->tensorlayer) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.21.0->tensorlayer) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.21.0->tensorlayer) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.21.0->tensorlayer) (2021.10.8)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15.0->tensorlayer) (3.2.2)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15.0->tensorlayer) (2021.11.2)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15.0->tensorlayer) (1.3.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15.0->tensorlayer) (2.6.3)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->tensorlayer) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->tensorlayer) (1.4.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->tensorlayer) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->tensorlayer) (3.0.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->tensorlayer) (4.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->tensorlayer) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->tensorlayer) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->tensorlayer) (3.1.0)\n","Installing collected packages: pillow, imageio, progressbar2, tensorlayer\n","  Attempting uninstall: pillow\n","    Found existing installation: Pillow 7.1.2\n","    Uninstalling Pillow-7.1.2:\n","      Successfully uninstalled Pillow-7.1.2\n","  Attempting uninstall: imageio\n","    Found existing installation: imageio 2.4.1\n","    Uninstalling imageio-2.4.1:\n","      Successfully uninstalled imageio-2.4.1\n","  Attempting uninstall: progressbar2\n","    Found existing installation: progressbar2 3.38.0\n","    Uninstalling progressbar2-3.38.0:\n","      Successfully uninstalled progressbar2-3.38.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed imageio-2.19.1 pillow-9.1.0 progressbar2-4.0.0 tensorlayer-2.2.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Number of GPUs available :  0\n"]},{"output_type":"execute_result","data":{"text/plain":["''"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["import tensorflow as tf\n","\n","import numpy as np\n","import os, time\n","\n","!pip install tensorlayer\n","\n","import tensorlayer as tl\n","\n","import csv, random, gc, pickle\n","import nibabel as nib\n","\n","print(\"Number of GPUs available : \", len(tf.config.list_physical_devices('GPU')))\n","\n","tf.test.gpu_device_name()\n","#exit(0)"]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kA0Cpnx54kNl","executionInfo":{"status":"ok","timestamp":1648474652051,"user_tz":-300,"elapsed":20334,"user":{"displayName":"Awais Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7HuAE6ug9F3m0qSui8SrTeNkmUoSCKKh8EBBZMg=s64","userId":"17510577265023244828"}},"outputId":"078925a6-0dd6-41a1-f338-5ad095a30145"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["\"\"\"\n","In seg file\n","--------------\n","Label 1: necrotic and non-enhancing tumor\n","Label 2: edema \n","Label 4: enhancing tumor\n","Label 0: background\n","\n","MRI\n","-------\n","whole/complete tumor: 1 2 4\n","core: 1 4\n","enhance: 4\n","\"\"\"\n","###============================= SETTINGS ===================================###\n","DATA_SIZE = 'small' # (small, half or all)\n","\n","save_dir = \"/content/drive/MyDrive/save_directory/data/train_dev_all/\"\n","if not os.path.exists(save_dir):\n","    os.makedirs(save_dir)\n","\n","HGG_data_path = \"/content/drive/MyDrive/Brats17TrainingData/HGG/\"\n","LGG_data_path = \"/content/drive/MyDrive/Brats17TrainingData/LGG/\"\n","survival_csv_path = \"/content/drive/MyDrive/Brats17TrainingData/survival_data.csv\"\n","###==========================================================================###\n","\n","survival_id_list = []\n","survival_age_list =[]\n","survival_peroid_list = []\n","\n","with open(survival_csv_path, 'r') as f:\n","    reader = csv.reader(f)\n","    next(reader)\n","    for idx, content in enumerate(reader):\n","        survival_id_list.append(content[0])\n","        survival_age_list.append(float(content[1]))\n","        survival_peroid_list.append(float(content[2]))\n","\n","print(len(survival_id_list)) #163\n","\n","if DATA_SIZE == 'all':\n","    HGG_path_list = tl.files.load_folder_list(path=HGG_data_path)\n","    LGG_path_list = tl.files.load_folder_list(path=LGG_data_path)\n","elif DATA_SIZE == 'half':\n","    HGG_path_list = tl.files.load_folder_list(path=HGG_data_path)[0:100]# DEBUG WITH SMALL DATA\n","    LGG_path_list = tl.files.load_folder_list(path=LGG_data_path)[0:30] # DEBUG WITH SMALL DATA\n","elif DATA_SIZE == 'small':\n","    HGG_path_list = tl.files.load_folder_list(path=HGG_data_path)[0:50] # DEBUG WITH SMALL DATA\n","    LGG_path_list = tl.files.load_folder_list(path=LGG_data_path)[0:20] # DEBUG WITH SMALL DATA\n","else:\n","    exit(\"Unknow DATA_SIZE\")\n","print(len(HGG_path_list), len(LGG_path_list)) #210 #75\n","\n","HGG_name_list = [os.path.basename(p) for p in HGG_path_list]\n","LGG_name_list = [os.path.basename(p) for p in LGG_path_list]\n","\n","survival_id_from_HGG = []\n","survival_id_from_LGG = []\n","for i in survival_id_list:\n","    if i in HGG_name_list:\n","        survival_id_from_HGG.append(i)\n","    elif i in LGG_name_list:\n","        survival_id_from_LGG.append(i)\n","    else:\n","        print(i)\n","\n","print(len(survival_id_from_HGG), len(survival_id_from_LGG)) #163, 0\n","\n","# use 42 from 210 (in 163 subset) and 15 from 75 as 0.8/0.2 train/dev split\n","\n","# use 126/42/42 from 210 (in 163 subset) and 45/15/15 from 75 as 0.6/0.2/0.2 train/dev/test split\n","index_HGG = list(range(0, len(survival_id_from_HGG)))\n","index_LGG = list(range(0, len(LGG_name_list)))\n","# random.shuffle(index_HGG)\n","# random.shuffle(index_HGG)\n","\n","if DATA_SIZE == 'all':\n","    dev_index_HGG = index_HGG[-84:-42]\n","    test_index_HGG = index_HGG[-42:]\n","    tr_index_HGG = index_HGG[:-84]\n","    dev_index_LGG = index_LGG[-30:-15]\n","    test_index_LGG = index_LGG[-15:]\n","    tr_index_LGG = index_LGG[:-30]\n","elif DATA_SIZE == 'half':\n","    dev_index_HGG = index_HGG[-30:]  # DEBUG WITH SMALL DATA\n","    test_index_HGG = index_HGG[-5:]\n","    tr_index_HGG = index_HGG[:-30]\n","    dev_index_LGG = index_LGG[-10:]  # DEBUG WITH SMALL DATA\n","    test_index_LGG = index_LGG[-5:]\n","    tr_index_LGG = index_LGG[:-10]\n","elif DATA_SIZE == 'small':\n","    dev_index_HGG = index_HGG[35:42]   # DEBUG WITH SMALL DATA\n","    # print(index_HGG, dev_index_HGG)\n","    # exit()\n","    test_index_HGG = index_HGG[41:42]\n","    tr_index_HGG = index_HGG[0:35]\n","    dev_index_LGG = index_LGG[7:10]    # DEBUG WITH SMALL DATA\n","    test_index_LGG = index_LGG[9:10]\n","    tr_index_LGG = index_LGG[0:7]\n","\n","survival_id_dev_HGG = [survival_id_from_HGG[i] for i in dev_index_HGG]\n","survival_id_test_HGG = [survival_id_from_HGG[i] for i in test_index_HGG]\n","survival_id_tr_HGG = [survival_id_from_HGG[i] for i in tr_index_HGG]\n","\n","survival_id_dev_LGG = [LGG_name_list[i] for i in dev_index_LGG]\n","survival_id_test_LGG = [LGG_name_list[i] for i in test_index_LGG]\n","survival_id_tr_LGG = [LGG_name_list[i] for i in tr_index_LGG]\n","\n","survival_age_dev = [survival_age_list[survival_id_list.index(i)] for i in survival_id_dev_HGG]\n","survival_age_test = [survival_age_list[survival_id_list.index(i)] for i in survival_id_test_HGG]\n","survival_age_tr = [survival_age_list[survival_id_list.index(i)] for i in survival_id_tr_HGG]\n","\n","survival_period_dev = [survival_peroid_list[survival_id_list.index(i)] for i in survival_id_dev_HGG]\n","survival_period_test = [survival_peroid_list[survival_id_list.index(i)] for i in survival_id_test_HGG]\n","survival_period_tr = [survival_peroid_list[survival_id_list.index(i)] for i in survival_id_tr_HGG]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ViksKseRy_sf","executionInfo":{"status":"ok","timestamp":1648474660143,"user_tz":-300,"elapsed":2836,"user":{"displayName":"Awais Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7HuAE6ug9F3m0qSui8SrTeNkmUoSCKKh8EBBZMg=s64","userId":"17510577265023244828"}},"outputId":"42589566-037f-4c64-e0a8-9bddf56af77c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["163\n","50 20\n","Brats17_TCIA_167_1\n","Brats17_TCIA_242_1\n","Brats17_TCIA_319_1\n","Brats17_TCIA_469_1\n","Brats17_TCIA_218_1\n","Brats17_TCIA_406_1\n","Brats17_TCIA_280_1\n","Brats17_TCIA_105_1\n","Brats17_TCIA_278_1\n","Brats17_TCIA_247_1\n","Brats17_TCIA_372_1\n","Brats17_TCIA_165_1\n","Brats17_TCIA_409_1\n","Brats17_TCIA_184_1\n","Brats17_TCIA_277_1\n","Brats17_TCIA_478_1\n","Brats17_TCIA_437_1\n","Brats17_TCIA_361_1\n","Brats17_TCIA_192_1\n","Brats17_TCIA_479_1\n","Brats17_TCIA_111_1\n","Brats17_TCIA_343_1\n","Brats17_TCIA_149_1\n","Brats17_TCIA_474_1\n","Brats17_TCIA_419_1\n","Brats17_TCIA_199_1\n","Brats17_TCIA_133_1\n","Brats17_TCIA_296_1\n","Brats17_TCIA_257_1\n","Brats17_TCIA_498_1\n","Brats17_TCIA_138_1\n","Brats17_TCIA_338_1\n","Brats17_TCIA_265_1\n","Brats17_TCIA_375_1\n","Brats17_TCIA_121_1\n","Brats17_TCIA_274_1\n","Brats17_TCIA_473_1\n","Brats17_TCIA_322_1\n","Brats17_TCIA_179_1\n","Brats17_TCIA_368_1\n","Brats17_TCIA_135_1\n","Brats17_TCIA_471_1\n","Brats17_TCIA_394_1\n","Brats17_TCIA_300_1\n","Brats17_TCIA_151_1\n","Brats17_TCIA_118_1\n","Brats17_TCIA_226_1\n","Brats17_TCIA_455_1\n","Brats17_TCIA_283_1\n","Brats17_TCIA_430_1\n","Brats17_TCIA_321_1\n","Brats17_TCIA_314_1\n","Brats17_TCIA_290_1\n","Brats17_TCIA_377_1\n","Brats17_TCIA_198_1\n","Brats17_TCIA_331_1\n","Brats17_TCIA_491_1\n","Brats17_TCIA_150_1\n","Brats17_TCIA_335_1\n","Brats17_TCIA_411_1\n","Brats17_TCIA_203_1\n","Brats17_TCIA_231_1\n","Brats17_TCIA_390_1\n","Brats17_TCIA_235_1\n","Brats17_TCIA_499_1\n","Brats17_TCIA_412_1\n","Brats17_TCIA_448_1\n","Brats17_TCIA_401_1\n","Brats17_TCIA_147_1\n","Brats17_TCIA_378_1\n","Brats17_TCIA_201_1\n","Brats17_TCIA_429_1\n","Brats17_TCIA_186_1\n","Brats17_TCIA_460_1\n","Brats17_TCIA_190_1\n","Brats17_TCIA_425_1\n","Brats17_CBICA_BHM_1\n","Brats17_CBICA_BHB_1\n","Brats17_CBICA_AZH_1\n","Brats17_CBICA_AZD_1\n","Brats17_CBICA_AYW_1\n","Brats17_CBICA_AYU_1\n","Brats17_CBICA_AYI_1\n","Brats17_CBICA_AYA_1\n","Brats17_CBICA_AXW_1\n","Brats17_CBICA_AXQ_1\n","Brats17_CBICA_AXO_1\n","Brats17_CBICA_AXN_1\n","Brats17_CBICA_AXM_1\n","Brats17_CBICA_AXL_1\n","Brats17_CBICA_AXJ_1\n","Brats17_CBICA_AWI_1\n","Brats17_CBICA_AWH_1\n","Brats17_CBICA_AWG_1\n","Brats17_CBICA_AVV_1\n","Brats17_CBICA_AVJ_1\n","Brats17_CBICA_AVG_1\n","Brats17_CBICA_AUR_1\n","Brats17_CBICA_AUQ_1\n","Brats17_CBICA_AUN_1\n","Brats17_CBICA_ATX_1\n","Brats17_CBICA_ATV_1\n","Brats17_CBICA_ATP_1\n","Brats17_CBICA_ATF_1\n","Brats17_CBICA_ATD_1\n","Brats17_CBICA_ATB_1\n","Brats17_CBICA_ASY_1\n","Brats17_CBICA_ASW_1\n","Brats17_CBICA_ASV_1\n","Brats17_CBICA_ASU_1\n","Brats17_CBICA_ASO_1\n","Brats17_CBICA_ASN_1\n","Brats17_CBICA_ASK_1\n","Brats17_CBICA_ASH_1\n","Brats17_CBICA_ASG_1\n","Brats17_CBICA_ASE_1\n","Brats17_CBICA_ASA_1\n","Brats17_CBICA_ARZ_1\n","Brats17_CBICA_ARW_1\n","Brats17_CBICA_ARF_1\n","Brats17_CBICA_AQZ_1\n","Brats17_CBICA_AQY_1\n","Brats17_CBICA_AQV_1\n","Brats17_CBICA_AQU_1\n","Brats17_CBICA_AQT_1\n","Brats17_CBICA_AQR_1\n","Brats17_CBICA_AQQ_1\n","Brats17_CBICA_AQP_1\n","Brats17_CBICA_AQO_1\n","Brats17_CBICA_AQN_1\n","Brats17_CBICA_AQJ_1\n","32 0\n"]}]},{"cell_type":"code","source":["\n","data_types = ['flair', 't1', 't1ce', 't2']\n","data_types_mean_std_dict = {i: {'mean': 0.0, 'std': 1.0} for i in data_types}\n","\n","# calculate mean and std for all data types\n","\n","# preserving_ratio = 0.0\n","# preserving_ratio = 0.01 # 0.118 removed\n","# preserving_ratio = 0.05 # 0.213 removed\n","# preserving_ratio = 0.10 # 0.359 removed\n","\n","\n","#==================== LOAD ALL IMAGES' PATH AND COMPUTE MEAN/ STD\n","for i in data_types:\n","    data_temp_list = []\n","    for j in HGG_name_list:\n","        img_path = os.path.join(HGG_data_path, j, j + '_' + i + '.nii.gz')\n","        img = nib.load(img_path).get_data()\n","        data_temp_list.append(img)\n","\n","    for j in LGG_name_list:\n","        img_path = os.path.join(LGG_data_path, j, j + '_' + i + '.nii.gz')\n","        img = nib.load(img_path).get_data()\n","        data_temp_list.append(img)\n","\n","    data_temp_list = np.asarray(data_temp_list)\n","    m = np.mean(data_temp_list)\n","    s = np.std(data_temp_list)\n","    data_types_mean_std_dict[i]['mean'] = m\n","    data_types_mean_std_dict[i]['std'] = s\n","del data_temp_list\n","print(data_types_mean_std_dict)\n","\n","with open(save_dir + 'mean_std_dict.pickle', 'wb') as f:\n","    pickle.dump(data_types_mean_std_dict, f, protocol=4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XhkZwjEx7QcL","outputId":"43ac0454-0f98-43b5-eea9-967bd231460a","executionInfo":{"status":"ok","timestamp":1648474832536,"user_tz":-300,"elapsed":163794,"user":{"displayName":"Awais Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7HuAE6ug9F3m0qSui8SrTeNkmUoSCKKh8EBBZMg=s64","userId":"17510577265023244828"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n","\n","* deprecated from version: 3.0\n","* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n","\n","* deprecated from version: 3.0\n","* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n"]},{"output_type":"stream","name":"stdout","text":["{'flair': {'mean': 40.16861452892985, 'std': 107.95231767823296}, 't1': {'mean': 56.732863208845366, 'std': 145.5254416514513}, 't1ce': {'mean': 58.47428745999744, 'std': 157.2972062062961}, 't2': {'mean': 59.905963008832565, 'std': 171.04426125128643}}\n"]}]},{"cell_type":"code","source":["##==================== GET NORMALIZE IMAGES\n","X_train_input = []\n","X_train_target = []\n","# X_train_target_whole = [] # 1 2 4\n","# X_train_target_core = [] # 1 4\n","# X_train_target_enhance = [] # 4\n","\n","X_dev_input = []\n","X_dev_target = []\n","# X_dev_target_whole = [] # 1 2 4\n","# X_dev_target_core = [] # 1 4\n","# X_dev_target_enhance = [] # 4"],"metadata":{"id":"OkCxcwu-qtLJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","print(\" HGG Validation\")\n","for i in survival_id_dev_HGG:\n","    all_3d_data = []\n","    for j in data_types:\n","        img_path = os.path.join(HGG_data_path, i, i + '_' + j + '.nii.gz')\n","        img = nib.load(img_path).get_data()\n","        img = (img - data_types_mean_std_dict[j]['mean']) / data_types_mean_std_dict[j]['std']\n","        img = img.astype(np.float32)\n","        all_3d_data.append(img)\n","\n","    seg_path = os.path.join(HGG_data_path, i, i + '_seg.nii.gz')\n","    seg_img = nib.load(seg_path).get_data()\n","    seg_img = np.transpose(seg_img, (1, 0, 2))\n","    for j in range(all_3d_data[0].shape[2]):\n","        combined_array = np.stack((all_3d_data[0][:, :, j], all_3d_data[1][:, :, j], all_3d_data[2][:, :, j], all_3d_data[3][:, :, j]), axis=2)\n","        combined_array = np.transpose(combined_array, (1, 0, 2))#.tolist()\n","        combined_array.astype(np.float32)\n","        X_dev_input.append(combined_array)\n","\n","        seg_2d = seg_img[:, :, j]\n","        # whole = np.zeros_like(seg_2d)\n","        # core = np.zeros_like(seg_2d)\n","        # enhance = np.zeros_like(seg_2d)\n","        # for index, x in np.ndenumerate(seg_2d):\n","        #     if x == 1:\n","        #         whole[index] = 1\n","        #         core[index] = 1\n","        #     if x == 2:\n","        #         whole[index] = 1\n","        #     if x == 4:\n","        #         whole[index] = 1\n","        #         core[index] = 1\n","        #         enhance[index] = 1\n","        # X_dev_target_whole.append(whole)\n","        # X_dev_target_core.append(core)\n","        # X_dev_target_enhance.append(enhance)\n","        seg_2d.astype(int)\n","        X_dev_target.append(seg_2d)\n","    del all_3d_data\n","    gc.collect()\n","    print(\"finished {}\".format(i))\n","\n","print(len(X_dev_input))\n","print()\n","print(len(X_dev_target))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZBD5Xxyd_mWB","outputId":"99aaa68a-ae51-49fd-a39c-a587971d1f37","executionInfo":{"status":"ok","timestamp":1648472853951,"user_tz":-300,"elapsed":773,"user":{"displayName":"Awais Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7HuAE6ug9F3m0qSui8SrTeNkmUoSCKKh8EBBZMg=s64","userId":"17510577265023244828"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" HGG Validation\n","0\n","\n","0\n"]}]},{"cell_type":"code","source":["print(\" LGG Validation\")\n","for i in survival_id_dev_LGG:\n","    all_3d_data = []\n","    for j in data_types:\n","        img_path = os.path.join(LGG_data_path, i, i + '_' + j + '.nii.gz')\n","        img = nib.load(img_path).get_data()\n","        img = (img - data_types_mean_std_dict[j]['mean']) / data_types_mean_std_dict[j]['std']\n","        img = img.astype(np.float32)\n","        all_3d_data.append(img)\n","\n","    seg_path = os.path.join(LGG_data_path, i, i + '_seg.nii.gz')\n","    seg_img = nib.load(seg_path).get_data()\n","    seg_img = np.transpose(seg_img, (1, 0, 2))\n","    for j in range(all_3d_data[0].shape[2]):\n","        combined_array = np.stack((all_3d_data[0][:, :, j], all_3d_data[1][:, :, j], all_3d_data[2][:, :, j], all_3d_data[3][:, :, j]), axis=2)\n","        combined_array = np.transpose(combined_array, (1, 0, 2))#.tolist()\n","        combined_array.astype(np.float32)\n","        X_dev_input.append(combined_array)\n","\n","        seg_2d = seg_img[:, :, j]\n","        # whole = np.zeros_like(seg_2d)\n","        # core = np.zeros_like(seg_2d)\n","        # enhance = np.zeros_like(seg_2d)\n","        # for index, x in np.ndenumerate(seg_2d):\n","        #     if x == 1:\n","        #         whole[index] = 1\n","        #         core[index] = 1\n","        #     if x == 2:\n","        #         whole[index] = 1\n","        #     if x == 4:\n","        #         whole[index] = 1\n","        #         core[index] = 1\n","        #         enhance[index] = 1\n","        # X_dev_target_whole.append(whole)\n","        # X_dev_target_core.append(core)\n","        # X_dev_target_enhance.append(enhance)\n","        seg_2d.astype(int)\n","        X_dev_target.append(seg_2d)\n","    del all_3d_data\n","    gc.collect()\n","    print(\"finished {}\".format(i))\n","\n","X_dev_input = np.asarray(X_dev_input, dtype=np.float32)\n","X_dev_target = np.asarray(X_dev_target)#, dtype=np.float32)\n","\n","\n","print(X_dev_input.shape)\n","print(X_dev_target.shape)\n","\n","print(len(X_dev_input))\n","print()\n","print(len(X_dev_target))\n","\n","with open(save_dir + 'dev_input.pickle', 'wb') as f:\n","  pickle.dump(X_dev_input, f, protocol=4)\n","with open(save_dir + 'dev_target.pickle', 'wb') as f:\n","  pickle.dump(X_dev_target, f, protocol=4)\n","\n","# del X_dev_input, X_dev_target\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sAKZHPjMe0-S","executionInfo":{"status":"ok","timestamp":1648472869198,"user_tz":-300,"elapsed":5597,"user":{"displayName":"Awais Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7HuAE6ug9F3m0qSui8SrTeNkmUoSCKKh8EBBZMg=s64","userId":"17510577265023244828"}},"outputId":"b6de17f9-eeff-495b-f540-6dc054cf6137"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" LGG Validation\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n","\n","* deprecated from version: 3.0\n","* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n","\n","* deprecated from version: 3.0\n","* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n","  if sys.path[0] == '':\n"]},{"output_type":"stream","name":"stdout","text":["finished Brats17_2013_6_1\n","finished Brats17_2013_8_1\n","finished Brats17_2013_9_1\n","(465, 240, 240, 4)\n","(465, 240, 240)\n","465\n","\n","465\n"]}]},{"cell_type":"code","source":["print(\" HGG Train\")\n","for i in survival_id_tr_HGG:\n","    all_3d_data = []\n","    for j in data_types:\n","        img_path = os.path.join(HGG_data_path, i, i + '_' + j + '.nii.gz')\n","        img = nib.load(img_path).get_data()\n","        img = (img - data_types_mean_std_dict[j]['mean']) / data_types_mean_std_dict[j]['std']\n","        img = img.astype(np.float32)\n","        all_3d_data.append(img)\n","\n","    seg_path = os.path.join(HGG_data_path, i, i + '_seg.nii.gz')\n","    seg_img = nib.load(seg_path).get_data()\n","    seg_img = np.transpose(seg_img, (1, 0, 2))\n","    for j in range(all_3d_data[0].shape[2]):\n","        combined_array = np.stack((all_3d_data[0][:, :, j], all_3d_data[1][:, :, j], all_3d_data[2][:, :, j], all_3d_data[3][:, :, j]), axis=2)\n","        combined_array = np.transpose(combined_array, (1, 0, 2))#.tolist()\n","        combined_array.astype(np.float32)\n","        X_train_input.append(combined_array)\n","\n","        seg_2d = seg_img[:, :, j]\n","        # whole = np.zeros_like(seg_2d)\n","        # core = np.zeros_like(seg_2d)\n","        # enhance = np.zeros_like(seg_2d)\n","        # for index, x in np.ndenumerate(seg_2d):\n","        #     if x == 1:\n","        #         whole[index] = 1\n","        #         core[index] = 1\n","        #     if x == 2:\n","        #         whole[index] = 1\n","        #     if x == 4:\n","        #         whole[index] = 1\n","        #         core[index] = 1\n","        #         enhance[index] = 1\n","        # X_train_target_whole.append(whole)\n","        # X_train_target_core.append(core)\n","        # X_train_target_enhance.append(enhance)\n","        seg_2d.astype(int)\n","        X_train_target.append(seg_2d)\n","    del all_3d_data\n","    print(\"finished {}\".format(i))\n","\n","\n","print(len(X_train_input))\n","print()\n","print(len(X_train_target))\n","\n","\"\"\"X_train_input = np.asarray(X_train_input, dtype=np.float32)\n","X_train_target = np.asarray(X_train_target)#, dtype=np.float32)\n","print(X_train_input.shape)\n","print(X_train_target.shape)\n","\n","with open(save_dir + 'train_input.pickle', 'wb') as f:\n","  pickle.dump(X_train_input, f, protocol=4)\n","with open(save_dir + 'train_target.pickle', 'wb') as f:\n","  pickle.dump(X_train_target, f, protocol=4)\"\"\"\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":889},"id":"SzruB_7ofJsO","executionInfo":{"status":"ok","timestamp":1648475189346,"user_tz":-300,"elapsed":61389,"user":{"displayName":"Awais Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7HuAE6ug9F3m0qSui8SrTeNkmUoSCKKh8EBBZMg=s64","userId":"17510577265023244828"}},"outputId":"f97a4bae-33cf-410b-ae9c-17a5398e9955"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" HGG Train\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n","\n","* deprecated from version: 3.0\n","* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n","\n","* deprecated from version: 3.0\n","* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n","  if sys.path[0] == '':\n"]},{"output_type":"stream","name":"stdout","text":["finished Brats17_2013_11_1\n","finished Brats17_2013_27_1\n","finished Brats17_CBICA_AQG_1\n","finished Brats17_CBICA_AQD_1\n","finished Brats17_CBICA_AQA_1\n","finished Brats17_CBICA_APZ_1\n","finished Brats17_CBICA_APY_1\n","finished Brats17_CBICA_APR_1\n","finished Brats17_CBICA_AOZ_1\n","finished Brats17_CBICA_AOP_1\n","finished Brats17_CBICA_AOO_1\n","finished Brats17_CBICA_AOH_1\n","finished Brats17_CBICA_AOD_1\n","finished Brats17_CBICA_ANZ_1\n","finished Brats17_CBICA_ANP_1\n","finished Brats17_CBICA_ANI_1\n","finished Brats17_CBICA_ANG_1\n","finished Brats17_CBICA_AMH_1\n","finished Brats17_CBICA_AME_1\n","finished Brats17_CBICA_ALX_1\n","finished Brats17_CBICA_ALU_1\n","finished Brats17_CBICA_ALN_1\n","finished Brats17_CBICA_ABY_1\n","finished Brats17_CBICA_ABO_1\n","finished Brats17_CBICA_ABN_1\n","finished Brats17_CBICA_ABM_1\n","finished Brats17_CBICA_ABE_1\n","finished Brats17_CBICA_ABB_1\n","finished Brats17_CBICA_AAP_1\n","finished Brats17_CBICA_AAL_1\n","finished Brats17_CBICA_AAG_1\n","finished Brats17_CBICA_AAB_1\n","4960\n","\n","4960\n"]},{"output_type":"execute_result","data":{"text/plain":["\"X_train_input = np.asarray(X_train_input, dtype=np.float32)\\nX_train_target = np.asarray(X_train_target)#, dtype=np.float32)\\nprint(X_train_input.shape)\\nprint(X_train_target.shape)\\n\\nwith open(save_dir + 'train_input.pickle', 'wb') as f:\\n  pickle.dump(X_train_input, f, protocol=4)\\nwith open(save_dir + 'train_target.pickle', 'wb') as f:\\n  pickle.dump(X_train_target, f, protocol=4)\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["print(\" LGG Train\")\n","for i in survival_id_tr_LGG:\n","    all_3d_data = []\n","    for j in data_types:\n","        img_path = os.path.join(LGG_data_path, i, i + '_' + j + '.nii.gz')\n","        img = nib.load(img_path).get_data()\n","        img = (img - data_types_mean_std_dict[j]['mean']) / data_types_mean_std_dict[j]['std']\n","        img = img.astype(np.float32)\n","        all_3d_data.append(img)\n","\n","    seg_path = os.path.join(LGG_data_path, i, i + '_seg.nii.gz')\n","    seg_img = nib.load(seg_path).get_data()\n","    seg_img = np.transpose(seg_img, (1, 0, 2))\n","    for j in range(all_3d_data[0].shape[2]):\n","        combined_array = np.stack((all_3d_data[0][:, :, j], all_3d_data[1][:, :, j], all_3d_data[2][:, :, j], all_3d_data[3][:, :, j]), axis=2)\n","        combined_array = np.transpose(combined_array, (1, 0, 2))#.tolist()\n","        combined_array.astype(np.float32)\n","        X_train_input.append(combined_array)\n","\n","        seg_2d = seg_img[:, :, j]\n","        # whole = np.zeros_like(seg_2d)\n","        # core = np.zeros_like(seg_2d)\n","        # enhance = np.zeros_like(seg_2d)\n","        # for index, x in np.ndenumerate(seg_2d):\n","        #     if x == 1:\n","        #         whole[index] = 1\n","        #         core[index] = 1\n","        #     if x == 2:\n","        #         whole[index] = 1\n","        #     if x == 4:\n","        #         whole[index] = 1\n","        #         core[index] = 1\n","        #         enhance[index] = 1\n","        # X_train_target_whole.append(whole)\n","        # X_train_target_core.append(core)\n","        # X_train_target_enhance.append(enhance)\n","        seg_2d.astype(int)\n","        X_train_target.append(seg_2d)\n","    del all_3d_data\n","    print(\"finished {}\".format(i))\n","\n","X_train_input = np.asarray(X_train_input, dtype=np.float32)\n","X_train_target = np.asarray(X_train_target)#, dtype=np.float32)\n","\"\"\"print(X_train_input.shape)\n","print(X_train_target.shape)\"\"\"\n","\n","print()\n","\n","print(len(X_train_input))\n","print(len(X_train_target))\n","\n","with open(save_dir + 'train_input.pickle', 'wb') as f:\n","  pickle.dump(X_train_input, f, protocol=4)\n","with open(save_dir + 'train_target.pickle', 'wb') as f:\n","  pickle.dump(X_train_target, f, protocol=4)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IHICCnB2d3XE","outputId":"ba229ee5-7fb2-411d-e672-7e3637aa7500"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" LGG Train\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n","\n","* deprecated from version: 3.0\n","* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n","\n","* deprecated from version: 3.0\n","* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n","  if sys.path[0] == '':\n"]},{"output_type":"stream","name":"stdout","text":["finished Brats17_2013_15_1\n","finished Brats17_2013_0_1\n","finished Brats17_2013_16_1\n","finished Brats17_2013_1_1\n","finished Brats17_2013_24_1\n","finished Brats17_2013_28_1\n","finished Brats17_2013_29_1\n","\n","6045\n","6045\n"]}]},{"cell_type":"code","source":["X_train_input = np.asarray(X_train_input, dtype=np.float32)\n","X_train_target = np.asarray(X_train_target)#, dtype=np.float32)\n","\n","print(X_train_input.shape)\n","print(X_train_target.shape)"],"metadata":{"id":"KfzioqQbfeD_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def distort_imgs(data):\n","    \"\"\" data augumentation \"\"\"\n","    x1, x2, x3, x4, y = data\n","    # x1, x2, x3, x4, y = tl.prepro.flip_axis_multi([x1, x2, x3, x4, y],  # previous without this, hard-dice=83.7\n","    #                         axis=0, is_random=True) # up down\n","    x1, x2, x3, x4, y = tl.prepro.flip_axis_multi([x1, x2, x3, x4, y],\n","                            axis=1, is_random=True) # left right\n","    x1, x2, x3, x4, y = tl.prepro.elastic_transform_multi([x1, x2, x3, x4, y],\n","                            alpha=720, sigma=24, is_random=True)\n","    x1, x2, x3, x4, y = tl.prepro.rotation_multi([x1, x2, x3, x4, y], rg=20,\n","                            is_random=True, fill_mode='constant') # nearest, constant\n","    x1, x2, x3, x4, y = tl.prepro.shift_multi([x1, x2, x3, x4, y], wrg=0.10,\n","                            hrg=0.10, is_random=True, fill_mode='constant')\n","    x1, x2, x3, x4, y = tl.prepro.shear_multi([x1, x2, x3, x4, y], 0.05,\n","                            is_random=True, fill_mode='constant')\n","    x1, x2, x3, x4, y = tl.prepro.zoom_multi([x1, x2, x3, x4, y],\n","                            zoom_range=[0.9, 1.1], is_random=True,\n","                            fill_mode='constant')\n","    return x1, x2, x3, x4, y"],"metadata":{"id":"tedNu2UIyMMR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def vis_imgs(X, y, path):\n","    \"\"\" show one slice \"\"\"\n","    if y.ndim == 2:\n","        y = y[:,:,np.newaxis]\n","    assert X.ndim == 3\n","    tl.vis.save_images(np.asarray([X[:,:,0,np.newaxis],\n","        X[:,:,1,np.newaxis], X[:,:,2,np.newaxis],\n","        X[:,:,3,np.newaxis], y]), size=(1, 5),\n","        image_path=path)\n","\n","def vis_imgs2(X, y_, y, path):\n","    \"\"\" show one slice with target \"\"\"\n","    if y.ndim == 2:\n","        y = y[:,:,np.newaxis]\n","    if y_.ndim == 2:\n","        y_ = y_[:,:,np.newaxis]\n","    assert X.ndim == 3\n","    tl.vis.save_images(np.asarray([X[:,:,0,np.newaxis],\n","        X[:,:,1,np.newaxis], X[:,:,2,np.newaxis],\n","        X[:,:,3,np.newaxis], y_, y]), size=(1, 6),\n","        image_path=path)"],"metadata":{"id":"KnWYaM3ZyTbX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main(task='all'):\n","    ## Create folder to save trained model and result images\n","    save_dir = \"checkpoint\"\n","    tl.files.exists_or_mkdir(save_dir)\n","    tl.files.exists_or_mkdir(\"samples/{}\".format(task))\n","\n","    ###======================== LOAD DATA ===================================###\n","    ## by importing this, you can load a training set and a validation set.\n","    # you will get X_train_input, X_train_target, X_dev_input and X_dev_target\n","    # there are 4 labels in targets:\n","    # Label 0: background\n","    # Label 1: necrotic and non-enhancing tumor\n","    # Label 2: edema\n","    # Label 4: enhancing tumor\n","    #import prepare_data_with_valid as dataset\n","    X_train = X_train_input\n","    y_train = X_train_target[:,:,:,np.newaxis]\n","    X_test = X_dev_input\n","    y_test = X_dev_target[:,:,:,np.newaxis]\n","\n","    if task == 'all':\n","        y_train = (y_train > 0).astype(int)\n","        y_test = (y_test > 0).astype(int)\n","    elif task == 'necrotic':\n","        y_train = (y_train == 1).astype(int)\n","        y_test = (y_test == 1).astype(int)\n","    elif task == 'edema':\n","        y_train = (y_train == 2).astype(int)\n","        y_test = (y_test == 2).astype(int)\n","    elif task == 'enhance':\n","        y_train = (y_train == 4).astype(int)\n","        y_test = (y_test == 4).astype(int)\n","    else:\n","        exit(\"Unknow task %s\" % task)\n","\n","    ###======================== HYPER-PARAMETERS ============================###\n","    batch_size = 10\n","    lr = 0.0001 \n","    # lr_decay = 0.5\n","    # decay_every = 100\n","    beta1 = 0.9\n","    n_epoch = 100\n","    print_freq_step = 100\n","\n","    ###======================== SHOW DATA ===================================###\n","    # show one slice\n","    X = np.asarray(X_train[80])\n","    y = np.asarray(y_train[80])\n","    # print(X.shape, X.min(), X.max()) # (240, 240, 4) -0.380588 2.62761\n","    # print(y.shape, y.min(), y.max()) # (240, 240, 1) 0 1\n","    nw, nh, nz = X.shape\n","    vis_imgs(X, y, 'samples/{}/_train_im.png'.format(task))\n","    # show data augumentation results\n","    for i in range(10):\n","        x_flair, x_t1, x_t1ce, x_t2, label = distort_imgs([X[:,:,0,np.newaxis], X[:,:,1,np.newaxis],\n","                X[:,:,2,np.newaxis], X[:,:,3,np.newaxis], y])#[:,:,np.newaxis]])\n","        # print(x_flair.shape, x_t1.shape, x_t1ce.shape, x_t2.shape, label.shape) # (240, 240, 1) (240, 240, 1) (240, 240, 1) (240, 240, 1) (240, 240, 1)\n","        X_dis = np.concatenate((x_flair, x_t1, x_t1ce, x_t2), axis=2)\n","        # print(X_dis.shape, X_dis.min(), X_dis.max()) # (240, 240, 4) -0.380588233471 2.62376139209\n","        vis_imgs(X_dis, label, 'samples/{}/_train_im_aug{}.png'.format(task, i))\n","\n","    with tf.device('/cpu:0'):\n","        sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n","        with tf.device('/gpu:0'): #<- remove it if you train on CPU or other GPU\n","            ###======================== DEFIINE MODEL =======================###\n","            ## nz is 4 as we input all Flair, T1, T1c and T2.\n","            t_image = tf.placeholder('float32', [batch_size, nw, nh, nz], name='input_image')\n","            ## labels are either 0 or 1\n","            t_seg = tf.placeholder('float32', [batch_size, nw, nh, 1], name='target_segment')\n","            ## train inference\n","            net = model.u_net(t_image, is_train=True, reuse=False, n_out=1)\n","            ## test inference\n","            net_test = model.u_net(t_image, is_train=False, reuse=True, n_out=1)\n","\n","            ###======================== DEFINE LOSS =========================###\n","            ## train losses\n","            out_seg = net.outputs\n","            dice_loss = 1 - tl.cost.dice_coe(out_seg, t_seg, axis=[0,1,2,3])#, 'jaccard', epsilon=1e-5)\n","            iou_loss = tl.cost.iou_coe(out_seg, t_seg, axis=[0,1,2,3])\n","            dice_hard = tl.cost.dice_hard_coe(out_seg, t_seg, axis=[0,1,2,3])\n","            loss = dice_loss\n","\n","            ## test losses\n","            test_out_seg = net_test.outputs\n","            test_dice_loss = 1 - tl.cost.dice_coe(test_out_seg, t_seg, axis=[0,1,2,3])#, 'jaccard', epsilon=1e-5)\n","            test_iou_loss = tl.cost.iou_coe(test_out_seg, t_seg, axis=[0,1,2,3])\n","            test_dice_hard = tl.cost.dice_hard_coe(test_out_seg, t_seg, axis=[0,1,2,3])\n","\n","        ###======================== DEFINE TRAIN OPTS =======================###\n","        t_vars = tl.layers.get_variables_with_name('u_net', True, True)\n","        with tf.device('/gpu:0'):\n","            with tf.variable_scope('learning_rate'):\n","                lr_v = tf.Variable(lr, trainable=False)\n","            train_op = tf.train.AdamOptimizer(lr_v, beta1=beta1).minimize(loss, var_list=t_vars)\n","\n","        ###======================== LOAD MODEL ==============================###\n","        tl.layers.initialize_global_variables(sess)\n","        ## load existing model if possible\n","        tl.files.load_and_assign_npz(sess=sess, name=save_dir+'/u_net_{}.npz'.format(task), network=net)\n","\n","        ###======================== TRAINING ================================###\n","    for epoch in range(0, n_epoch+1):\n","        epoch_time = time.time()\n","        ## update decay learning rate at the beginning of a epoch\n","        # if epoch !=0 and (epoch % decay_every == 0):\n","        #     new_lr_decay = lr_decay ** (epoch // decay_every)\n","        #     sess.run(tf.assign(lr_v, lr * new_lr_decay))\n","        #     log = \" ** new learning rate: %f\" % (lr * new_lr_decay)\n","        #     print(log)\n","        # elif epoch == 0:\n","        #     sess.run(tf.assign(lr_v, lr))\n","        #     log = \" ** init lr: %f  decay_every_epoch: %d, lr_decay: %f\" % (lr, decay_every, lr_decay)\n","        #     print(log)\n","\n","        total_dice, total_iou, total_dice_hard, n_batch = 0, 0, 0, 0\n","        for batch in tl.iterate.minibatches(inputs=X_train, targets=y_train,\n","                                    batch_size=batch_size, shuffle=True):\n","            images, labels = batch\n","            step_time = time.time()\n","            ## data augumentation for a batch of Flair, T1, T1c, T2 images\n","            # and label maps synchronously.\n","            data = tl.prepro.threading_data([_ for _ in zip(images[:,:,:,0, np.newaxis],\n","                    images[:,:,:,1, np.newaxis], images[:,:,:,2, np.newaxis],\n","                    images[:,:,:,3, np.newaxis], labels)],\n","                    fn=distort_imgs) # (10, 5, 240, 240, 1)\n","            b_images = data[:,0:4,:,:,:]  # (10, 4, 240, 240, 1)\n","            b_labels = data[:,4,:,:,:]\n","            b_images = b_images.transpose((0,2,3,1,4))\n","            b_images.shape = (batch_size, nw, nh, nz)\n","\n","            ## update network\n","            _, _dice, _iou, _diceh, out = sess.run([train_op,\n","                    dice_loss, iou_loss, dice_hard, net.outputs],\n","                    {t_image: b_images, t_seg: b_labels})\n","            total_dice += _dice; total_iou += _iou; total_dice_hard += _diceh\n","            n_batch += 1\n","\n","            ## you can show the predition here:\n","            # vis_imgs2(b_images[0], b_labels[0], out[0], \"samples/{}/_tmp.png\".format(task))\n","            # exit()\n","\n","            # if _dice == 1: # DEBUG\n","            #     print(\"DEBUG\")\n","            #     vis_imgs2(b_images[0], b_labels[0], out[0], \"samples/{}/_debug.png\".format(task))\n","\n","            if n_batch % print_freq_step == 0:\n","                print(\"Epoch %d step %d 1-dice: %f hard-dice: %f iou: %f took %fs (2d with distortion)\"\n","                % (epoch, n_batch, _dice, _diceh, _iou, time.time()-step_time))\n","\n","            ## check model fail\n","            if np.isnan(_dice):\n","                exit(\" ** NaN loss found during training, stop training\")\n","            if np.isnan(out).any():\n","                exit(\" ** NaN found in output images during training, stop training\")\n","\n","        print(\" ** Epoch [%d/%d] train 1-dice: %f hard-dice: %f iou: %f took %fs (2d with distortion)\" %\n","                (epoch, n_epoch, total_dice/n_batch, total_dice_hard/n_batch, total_iou/n_batch, time.time()-epoch_time))\n","\n","        ## save a predition of training set\n","        for i in range(batch_size):\n","            if np.max(b_images[i]) > 0:\n","                vis_imgs2(b_images[i], b_labels[i], out[i], \"samples/{}/train_{}.png\".format(task, epoch))\n","                break\n","            elif i == batch_size-1:\n","                vis_imgs2(b_images[i], b_labels[i], out[i], \"samples/{}/train_{}.png\".format(task, epoch))\n","\n","        ###======================== EVALUATION ==========================###\n","        total_dice, total_iou, total_dice_hard, n_batch = 0, 0, 0, 0\n","        for batch in tl.iterate.minibatches(inputs=X_test, targets=y_test,\n","                                        batch_size=batch_size, shuffle=True):\n","            b_images, b_labels = batch\n","            _dice, _iou, _diceh, out = sess.run([test_dice_loss,\n","                    test_iou_loss, test_dice_hard, net_test.outputs],\n","                    {t_image: b_images, t_seg: b_labels})\n","            total_dice += _dice; total_iou += _iou; total_dice_hard += _diceh\n","            n_batch += 1\n","\n","        print(\" **\"+\" \"*17+\"test 1-dice: %f hard-dice: %f iou: %f (2d no distortion)\" %\n","                (total_dice/n_batch, total_dice_hard/n_batch, total_iou/n_batch))\n","        print(\" task: {}\".format(task))\n","        ## save a predition of test set\n","        for i in range(batch_size):\n","            if np.max(b_images[i]) > 0:\n","                vis_imgs2(b_images[i], b_labels[i], out[i], \"samples/{}/test_{}.png\".format(task, epoch))\n","                break\n","            elif i == batch_size-1:\n","                vis_imgs2(b_images[i], b_labels[i], out[i], \"samples/{}/test_{}.png\".format(task, epoch))\n","\n","        ###======================== SAVE MODEL ==========================###\n","        tl.files.save_npz(net.all_params, name=save_dir+'/u_net_{}.npz'.format(task), sess=sess)"],"metadata":{"id":"NHOQE6J7ycgJ"},"execution_count":null,"outputs":[]}]}