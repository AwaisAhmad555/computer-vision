{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO6p72w5IZtfBkAm/zYZvQG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"dzRXM861zk4v","executionInfo":{"status":"ok","timestamp":1696076088853,"user_tz":-300,"elapsed":2688,"user":{"displayName":"Awais Ahmad","userId":"17510577265023244828"}}},"outputs":[],"source":["# Import the required libraries\n","from numpy import zeros, ones\n","from numpy.random import randn, randint\n","\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, Dropout\n","from tensorflow.keras.utils import plot_model\n","\n","from matplotlib import pyplot as plt"]},{"cell_type":"code","source":["#Remember that the discriminator is just a binary classifier for true/fake images.\n","def define_discriminator(in_shape=(256,256,1)):\n","\tmodel = Sequential()\n","\n"," # normal\n","\tmodel.add(Conv2D(128, (3,3), padding='same', input_shape=in_shape))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# normal\n","\tmodel.add(Conv2D(128, (3,3), padding='same', input_shape=in_shape))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# downsample to 64x64\n","\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# downsample to 32x32\n","\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# downsample to 16x16\n","\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# downsample to 8x8\n","\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# classifier\n","\tmodel.add(Flatten())\n","\tmodel.add(Dropout(0.4))\n","\tmodel.add(Dense(1, activation='sigmoid'))\n","\t# compile model\n","\topt = Adam(lr=0.0002, beta_1=0.5)\n","\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","\treturn model"],"metadata":{"id":"XWnEa5-R-lM7","executionInfo":{"status":"ok","timestamp":1696076127626,"user_tz":-300,"elapsed":434,"user":{"displayName":"Awais Ahmad","userId":"17510577265023244828"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#Verify the model summary\n","test_discr = define_discriminator()\n","print(test_discr.summary())"],"metadata":{"id":"C73-OubM-y7Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Remember that the input would be a latent vector (usually size 100)\n","def define_generator(latent_dim):\n","\tmodel = Sequential()\n","\t# Define number of nodes that can be gradually reshaped and upscaled to 128x128x3\n","\tn_nodes = 128 * 8 * 8 #8192 nodes\n","\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\tmodel.add(Reshape((8, 8, 128)))\n","\t# upsample to 16x16\n","\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# upsample to 32x32\n","\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# upsample to 64x64\n","\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# upsample to 128x128\n","\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n"," # upsample to 128x128\n","\tmodel.add(Conv2DTranspose(64, (4,4), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# output layer 128x128x3\n","\tmodel.add(Conv2D(1, (8,8), activation='tanh', padding='same')) #tanh goes from [-1,1]\n","\treturn model"],"metadata":{"id":"OEOyst-S-6HG","executionInfo":{"status":"ok","timestamp":1696076203731,"user_tz":-300,"elapsed":15,"user":{"displayName":"Awais Ahmad","userId":"17510577265023244828"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["test_gen = define_generator(100)\n","print(test_gen.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EH39_sMZAdRX","executionInfo":{"status":"ok","timestamp":1696076210057,"user_tz":-300,"elapsed":849,"user":{"displayName":"Awais Ahmad","userId":"17510577265023244828"}},"outputId":"cf86c455-0003-4def-bcb3-00d6c5baea23"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1 (Dense)             (None, 8192)              827392    \n","                                                                 \n"," leaky_re_lu_6 (LeakyReLU)   (None, 8192)              0         \n","                                                                 \n"," reshape (Reshape)           (None, 8, 8, 128)         0         \n","                                                                 \n"," conv2d_transpose (Conv2DTr  (None, 16, 16, 128)       262272    \n"," anspose)                                                        \n","                                                                 \n"," leaky_re_lu_7 (LeakyReLU)   (None, 16, 16, 128)       0         \n","                                                                 \n"," conv2d_transpose_1 (Conv2D  (None, 32, 32, 128)       262272    \n"," Transpose)                                                      \n","                                                                 \n"," leaky_re_lu_8 (LeakyReLU)   (None, 32, 32, 128)       0         \n","                                                                 \n"," conv2d_transpose_2 (Conv2D  (None, 64, 64, 128)       262272    \n"," Transpose)                                                      \n","                                                                 \n"," leaky_re_lu_9 (LeakyReLU)   (None, 64, 64, 128)       0         \n","                                                                 \n"," conv2d_transpose_3 (Conv2D  (None, 128, 128, 128)     262272    \n"," Transpose)                                                      \n","                                                                 \n"," leaky_re_lu_10 (LeakyReLU)  (None, 128, 128, 128)     0         \n","                                                                 \n"," conv2d_transpose_4 (Conv2D  (None, 256, 256, 64)      131136    \n"," Transpose)                                                      \n","                                                                 \n"," leaky_re_lu_11 (LeakyReLU)  (None, 256, 256, 64)      0         \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 256, 256, 1)       4097      \n","                                                                 \n","=================================================================\n","Total params: 2011713 (7.67 MB)\n","Trainable params: 2011713 (7.67 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["# define the combined generator and discriminator model, for updating the generator\n","def define_gan(g_model, d_model):\n","\t# make weights in the discriminator not trainable\n","\td_model.trainable = False\n","\t# connect them\n","\tmodel = Sequential()\n","\t# add generator\n","\tmodel.add(g_model)\n","\t# add the discriminator\n","\tmodel.add(d_model)\n","\t# compile model\n","\topt = Adam(lr=0.0002, beta_1=0.5)\n","\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n","\treturn model"],"metadata":{"id":"JBmkvXFfAhP1","executionInfo":{"status":"ok","timestamp":1696076226047,"user_tz":-300,"elapsed":19,"user":{"displayName":"Awais Ahmad","userId":"17510577265023244828"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["test_gan = define_gan(test_gen, test_discr)\n","print(test_gan.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-nPstQS5Ak50","executionInfo":{"status":"ok","timestamp":1696076228160,"user_tz":-300,"elapsed":52,"user":{"displayName":"Awais Ahmad","userId":"17510577265023244828"}},"outputId":"01943b41-1dd3-4039-8cb9-361a5c9bdbff"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," sequential_1 (Sequential)   (None, 256, 256, 1)       2011713   \n","                                                                 \n"," sequential (Sequential)     (None, 1)                 771969    \n","                                                                 \n","=================================================================\n","Total params: 2783682 (10.62 MB)\n","Trainable params: 2011713 (7.67 MB)\n","Non-trainable params: 771969 (2.94 MB)\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["# Function to sample some random real images\n","def generate_real_samples(dataset, n_samples):\n","\tix = randint(0, dataset.shape[0], n_samples)\n","\tX = dataset[ix]\n","\ty = ones((n_samples, 1)) # Class labels for real images are 1\n","\treturn X, y"],"metadata":{"id":"rHC5H9D4BXXO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to generate random latent points\n","def generate_latent_points(latent_dim, n_samples):\n","\tx_input = randn(latent_dim * n_samples)\n","\tx_input = x_input.reshape(n_samples, latent_dim) #Reshape to be provided as input to the generator.\n","\treturn x_input"],"metadata":{"id":"uvu_INXRBaO4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to generate fake images using latent vectors\n","def generate_fake_samples(g_model, latent_dim, n_samples):\n","\tx_input = generate_latent_points(latent_dim, n_samples) #Generate latent points as input to the generator\n","\tX = g_model.predict(x_input) #Use the generator to generate fake images\n","\ty = zeros((n_samples, 1)) # Class labels for fake images are 0\n","\treturn X, y"],"metadata":{"id":"pvP3ON8eBc9s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to save Plots after every n number of epochs\n","def save_plot(examples, epoch, n=10):\n","\t# scale images from [-1,1] to [0,1] so we can plot\n","\texamples = (examples + 1) / 2.0\n","\tfor i in range(n * n):\n","\t\tplt.subplot(n, n, 1 + i)\n","\t\tplt.axis('off')\n","\t\tplt.imshow(examples[i])\n","\t# save plot to a file so we can view how generated images evolved over epochs\n","  #filename = 'saved_data_during_training/images/generated_plot_128x128_e%03d.png' % (epoch+1)\n","\tfilename = 'generated_plot_128x128_e%03d.png' % (epoch+1)\n","\tplt.savefig(filename)\n","\tplt.close()"],"metadata":{"id":"_YqpvtMNBgEI","executionInfo":{"status":"ok","timestamp":1696076410516,"user_tz":-300,"elapsed":410,"user":{"displayName":"Awais Ahmad","userId":"17510577265023244828"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Function to summarize performance periodically.\n","#\n","def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n","\t# Fetch real images\n","\tX_real, y_real = generate_real_samples(dataset, n_samples)\n","\t# evaluate discriminator on real images - get accuracy\n","\t_, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n","\t# Generate fake images\n","\tx_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n","\t# evaluate discriminator on fake images - get accuracy\n","\t_, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n","\t# Print discriminate accuracies on ral and fake images.\n","\tprint('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n","\t# save generated images periodically using the save_plot function\n","\tsave_plot(x_fake, epoch)\n","\t# save the generator model\n","\tfilename = 'saved_data_during_training/models/generator_model_128x128_%03d.h5' % (epoch+1)\n","\tg_model.save(filename)"],"metadata":{"id":"BqDRXGrHCDeM","executionInfo":{"status":"ok","timestamp":1696076427656,"user_tz":-300,"elapsed":9,"user":{"displayName":"Awais Ahmad","userId":"17510577265023244828"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# train the generator and discriminator by enumerating batches and epochs.\n","#\n","def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=128):\n","\tbat_per_epo = int(dataset.shape[0] / n_batch)\n","\thalf_batch = int(n_batch / 2) #Disc. trained on half batch real and half batch fake images\n","\t#  enumerate epochs\n","\tfor i in range(n_epochs):\n","\t\t# enumerate batches\n","\t\tfor j in range(bat_per_epo):\n","\t\t\t# Fetch random 'real' images\n","\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n","\t\t\t# Train the discriminator using real images\n","\t\t\td_loss1, _ = d_model.train_on_batch(X_real, y_real)\n","\t\t\t# generate 'fake' images\n","\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n","\t\t\t# Train the discriminator using fake images\n","\t\t\td_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n","\t\t\t# Generate latent vectors as input for the generator\n","\t\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n","\t\t\t# Label generated (fake) mages as 1 to fool the discriminator\n","\t\t\ty_gan = ones((n_batch, 1))\n","\t\t\t# Train the generator (via the discriminator's error)\n","\t\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n","\t\t\t# Report disc. and gen losses.\n","\t\t\tprint('Epoch>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n","\t\t\t\t(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n","\t\t# evaluate the model performance, sometimes\n","\t\tif (i+1) % 10 == 0:\n","\t\t\tsummarize_performance(i, g_model, d_model, dataset, latent_dim)"],"metadata":{"id":"6BgHHGBqCIIC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"PbpOU3W9Citw"}},{"cell_type":"code","source":["import os\n","import numpy as np\n"],"metadata":{"id":"kPcHvZU-CuU_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","gpath = drive.mount('/content/drive')"],"metadata":{"id":"KBAUHUtMCcPF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = '/content/drive/MyDrive/ct scans/'\n","\n","print(os.listdir(path))"],"metadata":{"id":"shvNTT2GCmwv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i = 0\n","for npz_name in os.listdir(path):\n","\n","  complete_address = os.path.join(path,npz_name)\n","\n","  file_extension = complete_address.split(\".\")[-1]\n","\n","  if file_extension == \"npz\":\n","\n","\n","    ct_scans = np.load(complete_address)\n","\n","    if i == 0:\n","      complete_array = ct_scans[\"arr_0\"]\n","\n","      complete_array = np.transpose(complete_array, (1,2,0))\n","      pass\n","\n","    if i > 0:\n","\n","      ct_scan_array = ct_scans[\"arr_0\"]\n","\n","      if ct_scan_array.shape[0] != 256:\n","\n","        ct_scan_array = np.transpose(ct_scan_array, (1,2,0))\n","        pass\n","\n","\n","      complete_array = np.concatenate((complete_array, ct_scan_array),axis=2)\n","\n","      print(ct_scan_array.shape)\n","\n","      pass\n","\n","    pass\n","\n","  i = i + 1\n","\n","  pass\n","\n"],"metadata":{"id":"4tTAAoKHCr5d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_list = []\n","\n","for i in range(complete_array.shape[2]):\n","\n","  dataset_list.append(np.expand_dims(complete_array[:,:,i], axis = 2))\n","\n","  pass"],"metadata":{"id":"zczm86qWCysE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = np.array(dataset_list)"],"metadata":{"id":"k-Yz3a8jC8qT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot 25 images\n","for i in range(25):\n","\tplt.subplot(5, 5, 1 + i)\n","\tplt.axis('off')\n","\tplt.imshow(dataset[i*6])\n","plt.show()"],"metadata":{"id":"otdc7p_0DCly"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#size of the latent space\n","latent_dim = 100\n","# create the discriminator using our pre-defined function\n","d_model = define_discriminator()\n","# create the generator using our pre-defined function\n","g_model = define_generator(latent_dim)\n","# create the gan  using our pre-defined function\n","gan_model = define_gan(g_model, d_model)"],"metadata":{"id":"BXhquX1IDFEK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train model\n","train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100)"],"metadata":{"id":"mJewRDSIDRYO"},"execution_count":null,"outputs":[]}]}